
import yfinance as yf
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Fetch data from Yahoo Finance
def fetch_data_from_yahoo(ticker, period='5y'):
    data = yf.download(ticker, period=period, interval='1d')
    if data.empty:
        raise ValueError(f"No data found for ticker {ticker}")
    data.reset_index(inplace=True)
    data.rename(columns={'Date': 'Date', 'Open': 'Open', 'High': 'High', 'Low': 'Low', 'Close': 'Close', 'Volume': 'Volume'}, inplace=True)
    data['NetChange'] = data['Close'].diff()
    return data

# Data normalization function
def normalize_data(df):
    sc = MinMaxScaler()
    Featured_Data_Close = df[['Close']].values
    DataScaler_Close = sc.fit(Featured_Data_Close)
    X = DataScaler_Close.transform(Featured_Data_Close)
    return X, DataScaler_Close

# Fetch and normalize data
ticker = "KC=F"
df = fetch_data_from_yahoo(ticker)
X, DataScaler_Close = normalize_data(df)

# Split data into samples
X_samples, y_samples = [], []
TimeSteps = 200  # next day's Price Prediction is based on last 200 past day's prices
for i in range(TimeSteps, len(X)):
    x_sample = X[i - TimeSteps:i]
    y_sample = X[i]
    X_samples.append(x_sample)
    y_samples.append(y_sample)

X_data, y_data = np.array(X_samples), np.array(y_samples)

# Train on the last 300 days of data
X_train = X_data[-300:]
y_train = y_data[-300:]

# Define Input shapes for LSTM
TimeSteps = X_train.shape[1]
TotalFeatures = X_train.shape[2]

# Model initialization
model_Close = Sequential([
    Bidirectional(LSTM(units=128, activation='relu', return_sequences=True), input_shape=(TimeSteps, TotalFeatures)),
    Dropout(0.3),
    Bidirectional(LSTM(units=64, activation='relu', return_sequences=True)),
    Dropout(0.3),
    LSTM(units=32, activation='relu'),
    Dense(units=16, activation='relu'),
    Dropout(0.2),
    Dense(units=1)
])

model_Close.compile(optimizer='adam', loss='mean_squared_error')

# Early stopping and model checkpoint
early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)

# Model training
history = model_Close.fit(X_train, y_train, batch_size=128, epochs=500, verbose=1, validation_split=0.1, callbacks=[early_stop, checkpoint])

# After training, 'best_model.h5' will contain the trained weights
